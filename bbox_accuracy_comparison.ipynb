{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aafe732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from model_evaluation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"apple\", \"avocado\", \"banana\", \"kiwi\", \"lemon\", \"orange\", \"pear\", \"pomegranate\", \"strawberry\", \"watermelon\"]\n",
    "TEST_IMAGES = \"dataset/split/test/images\"\n",
    "TEST_LABELS = \"dataset/split/test/labels\"\n",
    "CONFIDENCE = 0.5\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "RCNN_MODEL_WEIGHTS = Path(\"models/faster_rcnn_fruits.pth\")\n",
    "RCNN_OUTPUT_DIR = \"evaluation_results/faster_rcnn\"\n",
    "YOLOV8N_MODEL_WEIGHTS = Path(\"models/yolov8_fruits.pt\")\n",
    "YOLOV8N_OUTPUT_DIR = \"evaluation_results/yolov8\"\n",
    "YOLOV8M_MODEL_WEIGHTS = Path(\"models/yolov8m_fruits.pt\")\n",
    "YOLOV8M_OUTPUT_DIR = \"evaluation_results/yolov8m\"\n",
    "YOLO11L_MODEL_WEIGHTS = Path(\"models/yolov11l_fruits.pt\")\n",
    "YOLO11L_OUTPUT_DIR = \"evaluation_results/yolov11l\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dceb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d2773",
   "metadata": {},
   "source": [
    "Evaluation for Faster_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a267f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Faster R-CNN model...\n",
      "Found 131 test images\n",
      "Processing 10/131...\n",
      "Processing 20/131...\n",
      "Processing 30/131...\n",
      "Processing 40/131...\n",
      "Processing 50/131...\n",
      "Processing 60/131...\n",
      "Processing 70/131...\n",
      "Processing 80/131...\n",
      "Processing 90/131...\n",
      "Processing 100/131...\n",
      "Processing 110/131...\n",
      "Processing 120/131...\n",
      "Processing 130/131...\n",
      "\n",
      "Generating evaluation report...\n",
      "============================================================\n",
      "BOUNDING BOX EVALUATION REPORT: Faster R-CNN\n",
      "============================================================\n",
      "\n",
      "Confidence Threshold: 0.5\n",
      "\n",
      "------------------------------------------------------------\n",
      "PRIMARY METRICS\n",
      "------------------------------------------------------------\n",
      "mAP@0.5:          0.7930\n",
      "mAP@0.75:         0.7045\n",
      "mAP@[0.5:0.95]:   0.6330\n",
      "Mean IoU:         0.8935\n",
      "\n",
      "------------------------------------------------------------\n",
      "DETECTION METRICS (IoU@0.5)\n",
      "------------------------------------------------------------\n",
      "Recall:           0.8164\n",
      "Precision:        0.7286\n",
      "F1-Score:         0.7700\n",
      "\n",
      "------------------------------------------------------------\n",
      "ERROR ANALYSIS\n",
      "------------------------------------------------------------\n",
      "False Positives:  111\n",
      "False Negatives:  67\n",
      "Total Predictions: 409\n",
      "Total Ground Truths: 365\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Report saved to: evaluation_results/faster_rcnn\n",
      "\n",
      "============================================================\n",
      "FASTER_RCNN MODEL EVALUATION COMPLETE!\n",
      "============================================================\n",
      "mAP@0.5: 0.7930\n",
      "mAP@0.75: 0.7045\n",
      "Recall: 0.8164\n",
      "Precision: 0.7286\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "rcnn_metrics = evaluate_faster_rcnn(\n",
    "    model_weights_path=RCNN_MODEL_WEIGHTS,\n",
    "    test_image_dir=TEST_IMAGES,\n",
    "    test_label_dir=TEST_LABELS,\n",
    "    output_dir=RCNN_OUTPUT_DIR,\n",
    "    confidence_threshold=CONFIDENCE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "all_results['Faster_RCNN'] = rcnn_metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FASTER_RCNN MODEL EVALUATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@0.5: {rcnn_metrics.map_50:.4f}\")\n",
    "print(f\"mAP@0.75: {rcnn_metrics.map_75:.4f}\")\n",
    "print(f\"Recall: {rcnn_metrics.recall_50:.4f}\")\n",
    "print(f\"Precision: {rcnn_metrics.precision_50:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5878d83a",
   "metadata": {},
   "source": [
    "Evalution for Yolov8n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "yolov8n_metrics = evaluate_yolo(\n",
    "    model_weights_path=YOLOV8N_MODEL_WEIGHTS,\n",
    "    test_image_dir=TEST_IMAGES,\n",
    "    test_label_dir=TEST_LABELS,\n",
    "    output_dir=YOLOV8N_OUTPUT_DIR,\n",
    "    confidence_threshold=CONFIDENCE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "all_results['YoloV8n'] = yolov8n_metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOLOV8N MODEL EVALUATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@0.5: {yolov8n_metrics.map_50:.4f}\")\n",
    "print(f\"mAP@0.75: {yolov8n_metrics.map_75:.4f}\")\n",
    "print(f\"Recall: {yolov8n_metrics.recall_50:.4f}\")\n",
    "print(f\"Precision: {yolov8n_metrics.precision_50:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1689e",
   "metadata": {},
   "source": [
    "Evalution for Yolov8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46563deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "yolov8m_metrics = evaluate_yolo(\n",
    "    model_weights_path=YOLOV8M_MODEL_WEIGHTS,\n",
    "    test_image_dir=TEST_IMAGES,\n",
    "    test_label_dir=TEST_LABELS,\n",
    "    output_dir=YOLOV8M_OUTPUT_DIR,\n",
    "    confidence_threshold=CONFIDENCE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "all_results['YoloV8m'] = yolov8m_metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOLOV8M MODEL EVALUATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@0.5: {yolov8m_metrics.map_50:.4f}\")\n",
    "print(f\"mAP@0.75: {yolov8m_metrics.map_75:.4f}\")\n",
    "print(f\"Recall: {yolov8m_metrics.recall_50:.4f}\")\n",
    "print(f\"Precision: {yolov8m_metrics.precision_50:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f84ec",
   "metadata": {},
   "source": [
    "Evalution for Yolo11l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "yolo11l_metrics = evaluate_yolo(\n",
    "    model_weights_path=YOLO11L_MODEL_WEIGHTS,\n",
    "    test_image_dir=TEST_IMAGES,\n",
    "    test_label_dir=TEST_LABELS,\n",
    "    output_dir=YOLO11L_OUTPUT_DIR,\n",
    "    confidence_threshold=CONFIDENCE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "all_results['Yolo11l'] = yolo11l_metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOLOV8M MODEL EVALUATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@0.5: {yolo11l_metrics.map_50:.4f}\")\n",
    "print(f\"mAP@0.75: {yolo11l_metrics.map_75:.4f}\")\n",
    "print(f\"Recall: {yolo11l_metrics.recall_50:.4f}\")\n",
    "print(f\"Precision: {yolo11l_metrics.precision_50:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
